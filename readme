Ce reperotoire contient des analyses sur des données volumineuses qui sont en l'occurence des logs d'un serveur web, 
mais avant de les analyser des transformations sont requises pour mettre en forme les données ce que nous allons découvrir durant ce projet.

Mots clés: Python, Spark, PySpark, SQL, Parsers, Big Data, Statistiques déscriptives, Session   




Architecture du repertoire:
	* Repertoire "data": Contient les logs.
	* Repertoire "notebooks": Le notebook des analyses et visualisations des logs.
	* Repertoire "output": Contient les figures de data visualisation
	* Un fichier requirements contenant les libs python utilisées.	
    

Les données:
	* Mettre les logs dans le fichier acces.log (Exemple: http://www.almhuette-raith.at/apache-log/access.log)
	* Un fichier "léger" (acces_light.log) est crée pour valider les pipelines.




